# Configuration for adversarial SFT training
defaults:
- _self_
- model: qwen3_8b
- data: dolci_sft
- training: adversarial

# Experiment metadata
experiment:
  name: adversarial_sft
  seed: 0
  output_dir: out/${experiment.name}
  cache_dir: .cache/adv-thought
  cache_batch_size: 4  # Batch size for incremental cache generation

# Weights & Biases logging
wandb:
  enabled: true
  project: adversarial-thought
  entity:       # Set to your W&B entity or leave null for default
  tags:
  - sft
  - adversarial

# Hardware settings
hardware:
  device: cuda
  dtype: float16
  compile: false  # Disable compile for adversarial training (may cause issues with hooks)

# Hardware settings specifically for adversarial oracle inference (dataset generation).
# `target_gpu_utilization` can be set to a float in (0, 1), e.g. 0.5 to limit the
# oracle model to at most 50% of each GPU's memory, offloading the rest to CPU.
adversarial_hardware:
  target_gpu_utilization:

# Hydra settings
hydra:
  run:
    dir: hydra
